# YOLO-sign-language-detection

# âœ‹ Sign Language Detection using YOLO

## ğŸ”¹ Introduction  
This project implements **Sign Language Detection** using **YOLO (You Only Look Once)** trained on an image dataset of sign hand gestures.  
The model takes an input image and instantly predicts the **correct sign label**, making it useful for accessibility tools, communication systems, and real-time gesture recognition.

---

# ğŸš€ Features  
- ğŸ–¼ï¸ **Image-based Gesture Detection** (A, B, C â€¦ or custom signs)  
- âš¡ **Fast YOLO Inference** â€“ real-time capable  
- ğŸ¯ **High Accuracy** with custom-trained dataset  
- ğŸ“Š **Bounding Boxes + Class Labels**  
- ğŸ” **Supports Custom Dataset Expansion**

---

# ğŸ§  Tech Stack  
- **Python 3.x**  
- **YOLOv5 **  
- **OpenCV** â€“ image loading and visualization  
- **PyTorch** â€“ model training/inference  
- **LabelImg** â€“ annotation & dataset handling  

